{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zvq8RRNMpHCoQJTARksJfUKrpjdkkPDa",
      "authorship_tag": "ABX9TyOWjSKFuhAtkFjdPyH72lL2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TiagoIesbick/dashboard-etl/blob/main/dashboard_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "OVrDn1e7NcWP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Expense"
      ],
      "metadata": {
        "id": "LhL_JZHvUX5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating a dataframe with paid expenses data from 2002 to 2023\n",
        "\n",
        "# Define the folder path\n",
        "exp_folder_2002_2023 = pathlib.Path(r'/content/drive/MyDrive/Dashboard_data/Despesas/2002_2023')\n",
        "\n",
        "# Read all excel files efficiently\n",
        "df_list = [\n",
        "    pd.read_excel(expense_file).dropna(axis=1, how='all')\n",
        "    for expense_file in exp_folder_2002_2023.glob(\"*.xls\")\n",
        "]\n",
        "\n",
        "# Concatenate all DataFrames\n",
        "df_exp_2002_2023 = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# Rename and clean up columns\n",
        "df_exp_2002_2023 = df_exp_2002_2023[['CPTPAG', 'RESUL_PAGO', 'UNIDORC', 'PROJATIV', 'RUBRICA', 'VINCORC']].rename(columns={\n",
        "    'CPTPAG':'Comp.pagto.', 'RESUL_PAGO':'Result. pago', 'UNIDORC':'Unid. Orçam.', 'PROJATIV':'Proj/Ativ',\n",
        "    'RUBRICA':'Rubrica', 'VINCORC':'Vinc. Orçam.'\n",
        "})\n",
        "\n",
        "# Filter out rows with nan values in some columns\n",
        "df_exp_2002_2023 = df_exp_2002_2023.dropna(subset=['Comp.pagto.', 'Result. pago'], ignore_index=True)\n",
        "\n",
        "# Process categorical column efficiently\n",
        "df_exp_2002_2023['Elemento'] = df_exp_2002_2023['Rubrica'].astype(str).str[:6].astype(int)"
      ],
      "metadata": {
        "id": "3PW1jmH1OSWO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating a dataframe with paid expenses data from 2024 onwards\n",
        "\n",
        "# Define the folder path\n",
        "exp_folder_2024_onwards = pathlib.Path(r'/content/drive/MyDrive/Dashboard_data/Despesas/2024+')\n",
        "\n",
        "# Read all CSV files efficiently\n",
        "df_list = [\n",
        "    pd.read_csv(expense_file).dropna(axis=1, how='all')\n",
        "    for expense_file in exp_folder_2024_onwards.glob(\"*.csv\")\n",
        "]\n",
        "\n",
        "# Concatenate all DataFrames\n",
        "df_exp_2024_onwards = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# Convert financial columns efficiently\n",
        "cols_to_convert = ['valorpago', 'restospagarnaoprocessadospagos', 'restospagarprocessadospagos']\n",
        "df_exp_2024_onwards[cols_to_convert] = df_exp_2024_onwards[cols_to_convert].apply(\n",
        "    lambda col: pd.to_numeric(col.str.replace('R\\$ ', '', regex=True).str.replace(',', '.'), errors='coerce')\n",
        ")\n",
        "\n",
        "# Filter out rows with zero values in all columns to convert\n",
        "df_exp_2024_onwards = df_exp_2024_onwards[\n",
        "    df_exp_2024_onwards[cols_to_convert].ne(0).any(axis=1)\n",
        "]\n",
        "\n",
        "# Rename and clean up columns\n",
        "df_exp_2024_onwards.rename(columns={\n",
        "    'exercicio': 'YEAR', 'mes': 'MONTH', 'subacao': 'Proj/Ativ', 'unidadeorcamentaria': 'Unid. Orçam.'\n",
        "}, inplace=True)\n",
        "\n",
        "# Fix month values\n",
        "df_exp_2024_onwards['MONTH'] = df_exp_2024_onwards['MONTH'].replace({0: 1, 13: 12}).astype(int)\n",
        "\n",
        "# Convert date\n",
        "df_exp_2024_onwards['Comp.pagto.'] = pd.to_datetime(df_exp_2024_onwards[['YEAR', 'MONTH']].assign(DAY=1))\n",
        "\n",
        "# Process categorical columns efficiently\n",
        "df_exp_2024_onwards['Elemento'] = df_exp_2024_onwards['elementocompleto'].str[:8].str.replace('.', '', regex=False).astype(int)\n",
        "df_exp_2024_onwards['Rubrica'] = df_exp_2024_onwards['desdobramentocompleto'].str[:12].str.replace('.', '', regex=False).astype(int)\n",
        "\n",
        "# Sorting once before processing\n",
        "df_exp_2024_onwards.sort_values('Comp.pagto.', inplace=True, ignore_index=True)\n",
        "\n",
        "# Subtract the last nonzero appearance for target columns\n",
        "cols = ['Proj/Ativ', 'Rubrica', 'fonterecursos', 'YEAR']\n",
        "target_cols = ['restospagarnaoprocessadospagos', 'restospagarprocessadospagos']\n",
        "for target_col in target_cols:\n",
        "    df_exp_2024_onwards[target_col + '_prev'] = (\n",
        "        df_exp_2024_onwards.where(df_exp_2024_onwards[target_col] != 0).groupby(cols)[target_col].shift(1).fillna(0)\n",
        "    )\n",
        "    df_exp_2024_onwards[target_col] -= df_exp_2024_onwards[target_col + '_prev']\n",
        "\n",
        "# Compute final results\n",
        "df_exp_2024_onwards['Result. pago'] = df_exp_2024_onwards[cols_to_convert].sum(axis=1)\n",
        "\n",
        "# Final filter and reordering columns\n",
        "df_exp_2024_onwards = df_exp_2024_onwards[df_exp_2024_onwards['Result. pago'] != 0].reset_index(drop=True)\n",
        "df_exp_2024_onwards['Vinc. Orçam.'] = df_exp_2024_onwards['defonterecursos'].str[:4].astype(int)\n",
        "\n",
        "df_exp_2024_onwards = df_exp_2024_onwards[\n",
        "    ['Comp.pagto.', 'Result. pago', 'Unid. Orçam.', 'Proj/Ativ', 'Elemento', 'Rubrica', 'Vinc. Orçam.',\n",
        "     'deelemento', 'dedesdobramento', 'desubacao', 'deunidadeorcamentária', 'defonterecursos']\n",
        "]"
      ],
      "metadata": {
        "id": "R6EfR07D-voC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenating the expense dataframes\n",
        "relevant_columns = ['Comp.pagto.', 'Result. pago', 'Unid. Orçam.', 'Proj/Ativ', 'Elemento', 'Rubrica', 'Vinc. Orçam.']\n",
        "df_exp = pd.concat([df_exp_2002_2023, df_exp_2024_onwards[relevant_columns]], ignore_index=True)"
      ],
      "metadata": {
        "id": "LweHlDW4y7u0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Revenue**"
      ],
      "metadata": {
        "id": "_aM2s57eV8ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating a dataframe with revenue collected from 2004 to 2017\n",
        "\n",
        "revenue_file_2004_2017 = r'/content/drive/MyDrive/Dashboard_data/Receitas/2004_2017/2004_2017_Cubo_Antigo.xlsx'\n",
        "\n",
        "df_rev_2004_2017 = pd.read_excel(revenue_file_2004_2017)\n",
        "df_rev_2004_2017.drop(0, inplace=True)\n",
        "df_rev_2004_2017.drop('Valor Orçado', axis=1, inplace=True)\n",
        "df_rev_2004_2017.rename(columns={'Exercício': 'YEAR',\n",
        "                                 'Mês': 'MONTH',\n",
        "                                 'Rótulos de Linha': 'orgao',\n",
        "                                 'Vínculo Cod': 'vinculo',\n",
        "                                 'N6 Subalinea': 'desdobramento6',\n",
        "                                 'Valor Arrecadado': 'valor_arrecadado'}, inplace=True)\n",
        "df_rev_2004_2017['Data'] = pd.to_datetime(df_rev_2004_2017[['YEAR', 'MONTH']].assign(DAY=1))\n",
        "df_rev_2004_2017[['YEAR', 'orgao', 'MONTH', 'vinculo']] = df_rev_2004_2017[['YEAR', 'orgao', 'MONTH', 'vinculo']].astype('int64')\n",
        "df_rev_2004_2017 = df_rev_2004_2017.loc[df_rev_2004_2017['valor_arrecadado'] != 0].reset_index(drop=True)\n",
        "df_rev_2004_2017.sort_values('Data', inplace=True, ignore_index=True)\n",
        "\n",
        "df_rev_from_to_2004_2017 = pd.read_excel(r'/content/drive/MyDrive/Dashboard_data/utils/rev_from_to-2004_2017.xlsx')\n",
        "df_rev_from_to_2004_2017['rubrica'] = df_rev_from_to_2004_2017['rubricacompleta'].str.extract(r'^(\\d+)')\n",
        "df_rev_from_to_2004_2017[\"nome_rubrica\"] = df_rev_from_to_2004_2017[\"rubricacompleta\"].str.extract(r\"^\\d+\\s*-\\s*(.*)\")\n",
        "\n",
        "df_rev_2004_2017 = df_rev_2004_2017.merge(\n",
        "    df_rev_from_to_2004_2017[['vinculo', 'desdobramento6', 'rubrica', 'nome_rubrica']],\n",
        "    on=['vinculo', 'desdobramento6'], how='left'\n",
        ")"
      ],
      "metadata": {
        "id": "I7LDs_LNbEn1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating a dataframe with revenue collected from 2018 to 2023\n",
        "\n",
        "rev_folder_2018_2023 = pathlib.Path(r'/content/drive/MyDrive/Dashboard_data/Receitas/2018_2023')\n",
        "\n",
        "df_list = [\n",
        "    pd.read_excel(revenue_file).dropna(axis=1, how='all')\n",
        "    for revenue_file in rev_folder_2018_2023.glob(\"*.xlsx\")\n",
        "]\n",
        "\n",
        "df_rev_2018_2023 = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "df_rev_2018_2023.drop(columns=[\n",
        "    'valor_cancelado', 'valor_orcado', 'valor_lancado', 'valor_meta', 'informacao_complementar',\n",
        "    'nome_orgao', 'orgao', 'nome_orgao.1', 'digito', 'categoria', 'especie', 'desdobramento1',\n",
        "    'desdobramento2', 'desdobramento3', 'desdobramento4', 'desdobramento5'\n",
        "    ], inplace=True)\n",
        "\n",
        "df_rev_2018_2023 = df_rev_2018_2023.loc[(df_rev_2018_2023['orgao_raiz'] == 7000) & (df_rev_2018_2023['valor_arrecadado'] != 0)].reset_index(drop=True)\n",
        "df_rev_2018_2023.rename(columns={'ano': 'YEAR', 'mes': 'MONTH'}, inplace=True)\n",
        "df_rev_2018_2023['Data'] = pd.to_datetime(df_rev_2018_2023[['YEAR', 'MONTH']].assign(DAY=1))\n",
        "df_rev_2018_2023.sort_values('Data', inplace=True, ignore_index=True)\n",
        "\n",
        "df_rev_from_to_2018_2023 = pd.read_excel(r'/content/drive/MyDrive/Dashboard_data/utils/rev_from_to-2018_2023.xlsx')\n",
        "df_rev_from_to_2018_2023['rubrica_new'] = df_rev_from_to_2018_2023['rubricacompleta'].str.extract(r'^(\\d+)')\n",
        "df_rev_from_to_2018_2023[\"nome_rubrica\"] = df_rev_from_to_2018_2023[\"rubricacompleta\"].str.extract(r\"^\\d+\\s*-\\s*(.*)\")\n",
        "\n",
        "df_rev_2018_2023 = df_rev_2018_2023.merge(\n",
        "    df_rev_from_to_2018_2023.drop('rubricacompleta', axis=1), on='rubrica', how='left'\n",
        "    ).drop('rubrica', axis=1).rename(columns={'rubrica_new': 'rubrica'})"
      ],
      "metadata": {
        "id": "LthAQNv84hew"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating a dataframe with revenue collected from 2024 onwards\n",
        "\n",
        "rev_folder_2024_onwards = pathlib.Path(r'/content/drive/MyDrive/Dashboard_data/Receitas/2024+')\n",
        "\n",
        "df_list = [\n",
        "    pd.read_csv(revenue_file).dropna(axis=1, how='all')\n",
        "    for revenue_file in rev_folder_2024_onwards.glob(\"*.csv\")\n",
        "]\n",
        "\n",
        "df_rev_2024_onwards = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "df_rev_2024_onwards.drop(columns=[\n",
        "    'orgao', 'unidadegestora', 'gestao', 'unidadeorcamentaria', 'categoriaeconomica',\n",
        "    'especie', 'd1', 'dd2', 'd3', 'desdobramentosigef', 'codificacaotce', 'valorarrecadadobruto',\n",
        "    'valoratualizadoliquido', 'valordeducao', 'valordeducaoatualizado', 'valordeducaoorcado',\n",
        "    'valororcadoliquido', 'valorreceitaatualizado', 'valorreceitaorcado'\n",
        "    ], inplace=True)\n",
        "\n",
        "df_rev_2024_onwards.rename(columns={'exercicio': 'YEAR', 'mes': 'MONTH'}, inplace=True)\n",
        "df_rev_2024_onwards['Data'] = pd.to_datetime(df_rev_2024_onwards[['YEAR', 'MONTH']].assign(DAY=1))\n",
        "df_rev_2024_onwards.sort_values('Data', inplace=True, ignore_index=True)\n",
        "\n",
        "df_rev_2024_onwards['rubrica'] = df_rev_2024_onwards['rubricacompleta'].str.extract(r'^(\\d+)')\n",
        "df_rev_2024_onwards[\"nome_rubrica\"] = df_rev_2024_onwards[\"rubricacompleta\"].str.extract(r\"^\\d+\\s*-\\s*(.*)\")"
      ],
      "metadata": {
        "id": "FLs80NCXO3SV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating normalization dataframe of origin, type and rubric\n",
        "\n",
        "df_otr = df_rev_2024_onwards[['origem', 'tipo', 'rubrica', 'nome_rubrica']].drop_duplicates(keep='last').rename(\n",
        "    columns={'origem': 'o', 'tipo': 't', 'rubrica': 'r_int', 'nome_rubrica': 'nome_r'}\n",
        ")\n",
        "\n",
        "for column in ['o', 't']:\n",
        "  df_otr[column + '_int'] = df_otr[column].str.extract(r'^(\\d+)')\n",
        "  df_otr['nome_' + column] = df_otr[column].str.extract(r\"^\\d+\\s*-\\s*(.*)\")\n",
        "\n",
        "df_tipo = pd.read_excel(r'/content/drive/MyDrive/Dashboard_data/utils/df_tipo.xlsx', dtype=str)\n",
        "df_tipo['tipo_int'] = df_tipo['tipo'].str.extract(r'^(\\d+)')\n",
        "df_tipo[\"nome_tipo\"] = df_tipo['tipo'].str.extract(r\"^\\d+\\s*-\\s*(.*)\")\n",
        "df_tipo = df_tipo.merge(\n",
        "    df_otr[['t_int', 'nome_t']].drop_duplicates(subset='t_int', keep='last'),\n",
        "    left_on='tipo_int', right_on='t_int', how='left'\n",
        "    )\n",
        "df_tipo.loc[df_tipo['nome_t'].isna(), ['t_int', 'nome_t']] = df_tipo.loc[df_tipo['nome_t'].isna(), ['tipo_int', 'nome_tipo']].values\n",
        "df_tipo = df_tipo[['rubrica', 't_int', 'nome_t']].rename(columns={'rubrica': 'r_int'})\n",
        "\n",
        "df_otr = pd.concat([df_otr, df_tipo], ignore_index=True)"
      ],
      "metadata": {
        "id": "0rjyas67CdLQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows with nan or zero values in relevant column\n",
        "\n",
        "df_rev_2024_onwards = df_rev_2024_onwards.dropna(subset='valorrealizadoliquido', ignore_index=True)\n",
        "df_rev_2024_onwards = df_rev_2024_onwards.loc[df_rev_2024_onwards['valorrealizadoliquido'] != 0].reset_index(drop=True)\n",
        "df_rev_2024_onwards['vinculo'] = df_rev_2024_onwards['fonterecurso'].str.extract(r\"^\\d+\\s*-\\s*(\\d+)\").astype(int)\n",
        "df_rev_2024_onwards.rename(columns={'valorrealizadoliquido': 'valor_arrecadado'}, inplace=True)"
      ],
      "metadata": {
        "id": "fRO_Wn8hgDj7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenating the revenue dataframes and normalizing origin, type and rubric\n",
        "\n",
        "df_rev = pd.concat([df_rev_2004_2017, df_rev_2018_2023, df_rev_2024_onwards], ignore_index=True)\n",
        "df_rev = df_rev.merge(df_otr, left_on='rubrica', right_on='r_int', how='left')\n",
        "df_rev.loc[~df_rev['nome_r'].isna(), 'origem'] = df_rev['nome_r']\n",
        "df_rev.loc[~df_rev['nome_t'].isna(), 'tipo'] = df_rev['nome_t']\n",
        "df_rev.loc[~df_rev['nome_o'].isna(), 'origem'] = df_rev['nome_o']\n",
        "df_rev.loc[df_rev['nome_o'].isna(), 'origem'] = df_rev['rubrica'].str[:2].map(\n",
        "    df_otr[['o_int', 'nome_o']].drop_duplicates(keep='last').set_index('o_int')['nome_o']\n",
        "    )\n",
        "df_rev.loc[\n",
        "    (df_rev['origem'].isna()) &\n",
        "    (df_rev['rubrica'].str[:2] == '17'), 'origem'] = 'Transferências Correntes'"
      ],
      "metadata": {
        "id": "PkJrEGDlmdM4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Files"
      ],
      "metadata": {
        "id": "WpyJ-lNVUNBS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rA33izJLNIJc"
      },
      "outputs": [],
      "source": [
        "# Reading auxiliary tables\n",
        "\n",
        "file_path = r'/content/drive/MyDrive/Dashboard_data/utils/auxiliary_tables.xlsx'\n",
        "\n",
        "sheets_info = {\n",
        "    'n_uni': {'skiprows': 2, 'cols': ['uni']},\n",
        "    'n_proj': {'skiprows': 3, 'cols': ['proj', 'nome_proj']},\n",
        "    'n_elem': {'skiprows': 3, 'cols': ['elem', 'nome_elem']},\n",
        "    'n_vinc': {'skiprows': 3, 'cols': ['vinc', 'nome_vinc']},\n",
        "    'n_rub': {'skiprows': 3, 'cols': ['rub', 'nome_rub']}\n",
        "}\n",
        "\n",
        "dfs = {\n",
        "    sheet: pd.read_excel(file_path, sheet_name=sheet, skiprows=info['skiprows'], header=None, names=info['cols'])\n",
        "    for sheet, info in sheets_info.items()\n",
        "}\n",
        "\n",
        "for sheet, df in dfs.items():\n",
        "  if 'uni' in df.columns:\n",
        "      df['nome_uni'] = df['uni'].str[5:]\n",
        "      df['uni_int'] = df['uni'].str[:4].astype(int)\n",
        "  if 'proj' in df.columns:\n",
        "      df['proj_int'] = df['proj'].str[:4].astype(int)\n",
        "  if 'elem' in df.columns:\n",
        "      df['elem_int'] = df['elem'].str[:6].astype(int)\n",
        "  if 'rub' in df.columns:\n",
        "      df['rub_int'] = df['rub'].str[:12].astype('int64')\n",
        "  if 'vinc' in df.columns:\n",
        "      df['vinc_int'] = df['vinc'].str[:4].astype(int)\n",
        "\n",
        "df_uni, df_proj, df_elem, df_vinc, df_rub = dfs.values()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Updating the elements dataframe\n",
        "\n",
        "df_new_elem = df_exp_2024_onwards[['Elemento', 'deelemento']].drop_duplicates(keep='last').rename(columns={\n",
        "    'Elemento': 'elem_int',\n",
        "    'deelemento': 'nome_elem'\n",
        "})\n",
        "df_elem = pd.concat([df_elem, df_new_elem], ignore_index=True).drop_duplicates(subset='elem_int', keep='last').reset_index(drop=True)\n",
        "df_elem['elem'] = df_elem['elem_int'].astype(str) + ' - ' + df_elem['nome_elem'].str.title()"
      ],
      "metadata": {
        "id": "zlTJKehxFJw_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updating the rubric dataframe\n",
        "\n",
        "df_new_rub = df_exp_2024_onwards[['Rubrica', 'dedesdobramento']].drop_duplicates(keep='last').rename(columns={\n",
        "    'Rubrica': 'rub_int',\n",
        "    'dedesdobramento': 'nome_rub'\n",
        "})\n",
        "df_rub = pd.concat([df_rub, df_new_rub], ignore_index=True).drop_duplicates(subset='rub_int', keep='last').reset_index(drop=True)\n",
        "df_rub['rub'] = df_rub['rub_int'].astype(str) + ' - ' + df_rub['nome_rub'].str.title()"
      ],
      "metadata": {
        "id": "R9IEYOptSTte"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updating the project dataframe\n",
        "\n",
        "df_new_proj = df_exp_2024_onwards[['Proj/Ativ', 'desubacao']].drop_duplicates(keep='last').rename(columns={\n",
        "    'Proj/Ativ': 'proj_int',\n",
        "    'desubacao': 'nome_proj'\n",
        "})\n",
        "df_proj = pd.concat([df_proj, df_new_proj], ignore_index=True).drop_duplicates(subset='proj_int', keep='last').reset_index(drop=True)\n",
        "df_proj['proj'] = df_proj['proj_int'].astype(str) + ' - ' + df_proj['nome_proj'].str.title()"
      ],
      "metadata": {
        "id": "rGmVqSx6Zo8a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updating the budget units dataframe\n",
        "\n",
        "df_new_uni = df_exp_2024_onwards[['Unid. Orçam.', 'deunidadeorcamentária']].drop_duplicates(keep='last').rename(columns={\n",
        "    'Unid. Orçam.': 'uni_int',\n",
        "    'deunidadeorcamentária': 'nome_uni'\n",
        "})\n",
        "df_uni = pd.concat([df_uni, df_new_uni], ignore_index=True).drop_duplicates(subset='uni_int', keep='last').reset_index(drop=True)\n",
        "df_uni['uni'] = df_uni['uni_int'].astype(str) + ' - ' + df_uni['nome_uni'].str.title()"
      ],
      "metadata": {
        "id": "P1VOjS1ebJe9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updating the entail dataframe\n",
        "\n",
        "df_new_vinc_exp = df_exp_2024_onwards[['Vinc. Orçam.', 'defonterecursos']].drop_duplicates(keep='last').rename(columns={\n",
        "    'Vinc. Orçam.': 'vinc_int', 'defonterecursos': 'nome_vinc'\n",
        "})\n",
        "df_new_vinc_exp['nome_vinc'] = df_new_vinc_exp['nome_vinc'].str.split('-').str.get(1).str.strip()\n",
        "\n",
        "df_new_vinc_rev = df_rev_2024_onwards[['fonterecurso', 'vinculo']].drop_duplicates(keep='last').rename(columns={\n",
        "    'vinculo': 'vinc_int', 'fonterecurso': 'nome_vinc'\n",
        "})\n",
        "df_new_vinc_rev['nome_vinc'] = df_new_vinc_rev['nome_vinc'].str.extract(r\"^\\d+\\s*-\\s*\\d+\\s*-\\s*(.*)\")\n",
        "\n",
        "df_vinc = pd.concat([df_vinc, df_new_vinc_exp, df_new_vinc_rev], ignore_index=True).drop_duplicates(subset='vinc_int', keep='last').reset_index(drop=True)\n",
        "\n",
        "common_values = set(df_exp['Vinc. Orçam.']) | set(df_rev['vinculo'])\n",
        "df_vinc = df_vinc[df_vinc['vinc_int'].isin(common_values)]\n",
        "\n",
        "df_vinc['vinc'] = df_vinc['vinc_int'].astype(str) + ' - ' + df_vinc['nome_vinc'].str.title()"
      ],
      "metadata": {
        "id": "4VGOqDuamYEB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the files\n",
        "\n",
        "final_data_folder = pathlib.Path(r'/content/drive/MyDrive/Dashboard_data/final_data')\n",
        "\n",
        "df_uni.sort_values('uni_int').to_csv(final_data_folder / 'df_uni.csv', encoding='utf-8-sig', sep=';', index=False)\n",
        "df_proj.sort_values('proj_int').to_csv(final_data_folder / 'df_proj.csv', encoding='utf-8-sig', sep=';', index=False)\n",
        "df_elem.sort_values('elem_int').to_csv(final_data_folder / 'df_elem.csv', encoding='utf-8-sig', sep=';', index=False)\n",
        "df_rub.sort_values('rub_int').to_csv(final_data_folder / 'df_rub.csv', encoding='utf-8-sig', sep=';', index=False)\n",
        "df_vinc.sort_values('vinc_int').to_csv(final_data_folder / 'df_vinc.csv', encoding='utf-8-sig', sep=';', index=False)\n",
        "df_exp.sort_values('Comp.pagto.').to_csv(final_data_folder / 'df_exp.csv', encoding='utf-8-sig', sep=';', index=False)\n",
        "df_rev[['Data', 'vinculo', 'origem', 'tipo', 'nome_rubrica', 'valor_arrecadado']].sort_values('Data').to_csv(\n",
        "    final_data_folder / 'df_rev.csv', encoding='utf-8-sig', sep=';', index=False\n",
        ")"
      ],
      "metadata": {
        "id": "8vhtlCYuV7ui"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}